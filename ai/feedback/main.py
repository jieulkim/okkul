import os
import asyncio
import json
import time
import httpx
from typing import List
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(title="ì˜¤í”½ê¿€ì¼ AI ë¶„ì„ ì„œë²„ (Sequential Gemini ë²„ì „)")

GMS_KEY = os.environ.get("GMS_KEY")
GEMINI_URL = "https://gms.ssafy.io/gmsapi/generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent"

# --- Pydantic ëª¨ë¸ ì •ì˜ ---

class AnalysisRequest(BaseModel):
    question_text: str = Field(..., description="ì˜¤í”½ ì§ˆë¬¸ í…ìŠ¤íŠ¸", example="Tell me about your favorite park.")
    user_answer: str = Field(..., description="ì‚¬ìš©ìê°€ ë°œí™”í•œ ì˜ì–´ ë‹µë³€", example="I like Central Park...")
    user_korean_script: str = Field(..., description="ì‚¬ìš©ìê°€ ë§í•˜ê³  ì‹¶ì—ˆë˜ í•œêµ­ì–´ ì˜ë„", example="ë‚˜ëŠ” ì„¼íŠ¸ëŸ´ íŒŒí¬ë¥¼ ì¢‹ì•„í•´. ê±°ê¸° ê°€ë©´ ë§ˆìŒì´ í¸í•´ì§€ê±°ë“ .")

class SentenceFeedback(BaseModel):
    target_sentence: str = Field(..., description="ì›ë³¸ ë¬¸ì¥")
    target_text: str = Field(..., description="ìˆ˜ì •ì´ í•„ìš”í•œ ë¶€ë¶„")
    improved_text: str = Field(..., description="êµì •ëœ ì „ì²´ ë¬¸ì¥")
    feedback: str = Field(..., description="êµì • ì´ìœ  ë° AL íŒ")
    sentence_order: int = Field(..., description="ë¬¸ì¥ ìˆœì„œ")

class CombinedResponse(BaseModel):
    improved_answer: str
    relevance_feedback: str
    logic_feedback: str
    fluency_feedback: str
    sentence_details: List[SentenceFeedback]

# --- ì—ì´ì „íŠ¸ í•¨ìˆ˜ ---

async def analyze_sentences_gemini(text: str):
    """1ë‹¨ê³„: ë¬¸ì¥ ë‹¨ìœ„ êµì • ë° í•„ëŸ¬(Filler) ì£¼ì…"""
    start_time = time.perf_counter()
    headers = {"Content-Type": "application/json", "x-goog-api-key": GMS_KEY}
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì˜¤í”½ ë¬¸ì¥ êµì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì‚¬ìš©ì ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ AL ë“±ê¸‰ì— ë§ê²Œ êµì •í•˜ì„¸ìš”.
    
    [êµì • ê°€ì´ë“œë¼ì¸]
    ì¤‘ìš”: í•´ë‹¹ ë¬¸ì¥ì´ ì–´ëŠì •ë„ ì™„ë²½í•˜ë©´ êµì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    1. ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì •ì€ ê¸°ë³¸ì…ë‹ˆë‹¤.
    2. ë¬¸ì¥ ì‚¬ì´ì— ìì—°ìŠ¤ëŸ¬ìš´ Filler(you know, I mean, I gotta say, What I'm trying to say is, Well, actually I've never thought about it...) ë“±ì„ í•„ìš”í•˜ë‹¤ë©´ ì¶”ê°€í•˜ì„¸ìš”.
    3. êµ¬ì–´ì²´ í˜•íƒœë¡œ, ê°ì • í‘œí˜„ì„ ë”ìš± í’ë¶€í•˜ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”. (numerous, incredibly, crystal clear, stunning, go-to, laid back, relaxing, striking, challenging, various, truly, tasty ë“± ì‚¬ìš©)
    4. ë¡¤í”Œë ˆì´ë‚˜ ê³¼ê±°ì™€ í˜„ì¬ë¥¼ ë¹„êµí•  ë• ì™„ë£Œ ì‹œì œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

    ì‘ë‹µ í˜•ì‹ (JSON):
    {{
      "sentences": [
        {{
          "target_sentence": "ì›ë˜ ë¬¸ì¥ ì „ì²´",
          "target_text": "ì˜¤ë¥˜/ê°œì„  êµ¬ê°„",
          "improved_text": "êµì •ëœ ë¬¸ì¥ ì „ì²´",
          "feedback": "êµì • ì´ìœ  ë° AL íŒ (100ì ì´ë‚´)",
          "sentence_order": 1
        }}
      ]
    }}
    ì‚¬ìš©ì ë‹µë³€: {text}
    """
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"response_mime_type": "application/json"}
    }

    async with httpx.AsyncClient() as client:
        response = await client.post(GEMINI_URL, headers=headers, json=payload, timeout=30.0)
        res_json = response.json()
    
    content_text = res_json['candidates'][0]['content']['parts'][0]['text']
    sentences = json.loads(content_text).get("sentences", [])
    
    print(f"ğŸ“Š [Step 1] ë¬¸ì¥ êµì • ì™„ë£Œ ({time.perf_counter() - start_time:.2f}s)")
    return sentences

async def analyze_overall_gemini(question: str, user_answer: str, corrected_text: str, user_korean_script: str):
    """2ë‹¨ê³„: êµì •ë³¸ìœ¼ë¡œ ëª¨ë²” ë‹µì•ˆì„ ìƒì„±í•˜ë˜, í•œêµ­ì–´ ìŠ¤í¬ë¦½íŠ¸ ëŒ€ì¡° ë° ì›ë³¸ ê¸°ì¤€ í‰ê°€ ìˆ˜í–‰"""
    start_time = time.perf_counter()
    headers = {"Content-Type": "application/json", "x-goog-api-key": GMS_KEY}
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì˜¤í”½(OPIc) AL ì „ë¬¸ ì±„ì ê´€ì…ë‹ˆë‹¤. 
    ì•„ë˜ ì œê³µëœ [ì›ë³¸ ë‹µë³€] ë° [í•œêµ­ì–´ ì˜ë„]ë¥¼ ë¶„ì„í•˜ì—¬ í”¼ë“œë°±í•˜ê³ , [êµì •ëœ ë¬¸ì¥ë“¤]ì„ í™œìš©í•´ ìµœì¢… í•™ìŠµìš© ëª¨ë²” ë‹µì•ˆì„ ë§Œë“œì„¸ìš”.

    [ì…ë ¥ ë°ì´í„°]
    - ì§ˆë¬¸: {question}
    - í•œêµ­ì–´ ì˜ë„(ì‚¬ìš©ìê°€ ë§í•˜ê³  ì‹¶ì—ˆë˜ ë‚´ìš©): {user_korean_script}
    - ì›ë³¸ ë‹µë³€(ì‚¬ìš©ì ì‹¤ì œ ë°œí™”): {user_answer}
    - êµì •ëœ ë¬¸ì¥ë“¤(1ë‹¨ê³„ ê²°ê³¼ë¬¼): {corrected_text}

    [ì‘ì„± ê·œì¹™ - ë°˜ë“œì‹œ JSON í¬ë§·ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”]
    1. improved_answer: [êµì •ëœ ë¬¸ì¥ë“¤]ì˜ ë‚´ìš©ì„ ìœ ì§€í•˜ë©°, ì „ì²´ íë¦„ì´ ìì—°ìŠ¤ëŸ½ë„ë¡ ì—°ê²° ì–´êµ¬ë§Œ ì¶”ê°€í•˜ì—¬ ì™„ì„±í•˜ì„¸ìš”.
       - ì„œë‘ì— í™•ì‹¤í•œ Main Point(MP)ê°€ ë“œëŸ¬ë‚˜ì•¼ í•©ë‹ˆë‹¤.
       - í•œêµ­ì–´ ì˜ë„ì—ëŠ” ìˆìœ¼ë‚˜ ì˜ì–´ ë‹µë³€ì—ì„œ ëˆ„ë½ëœ í•µì‹¬ ë‚´ìš©ì´ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ì‹œì¼œ ì™„ì„±í•˜ì„¸ìš”.
       - COMBO ë¬¸ì œê±°ë‚˜, ì´ì „ì— ë§í•œ ë‚´ìš©ì´ ì–¸ê¸‰ë  ë• "As I told you before"ì™€ ê°™ì€ ì—°ê²° ê³ ë¦¬ë¥¼ ë„£ìœ¼ì„¸ìš”.
       - ê·¸ ì™¸ì— ë¬¸ì¥ ì—°ê²° ê°„ì— í•„ìš”í•œ í•„ëŸ¬ë¥¼ ë¬¸ë§¥ìƒ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”. (I think that's all I can say about me, That's all I wanted to say, What I'm trying to say, To put detail~ , At the end of the day, Or something, Obviously, Currently, basically, You see, I mean, In fact, what else- , What I really love about is that, The reason why, what am I trying to say, anyway, I gotta tell you, Wow... It's quite a tough question, That's tricky, That is a reason why)
       - ì• ë’¤ ë¬¸ì¥ì˜ ë§¥ë½ì´ ë‹¬ë¼ì§ˆ ë• By the way ë“±ì˜ ì ‘ì†ì‚¬ë¥¼ ì ì ˆí•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”. 

    2. relevance_feedback: [ì›ë³¸ ë‹µë³€]ì´ ì§ˆë¬¸ì˜ ì˜ë„ì— ë¶€í•©í•˜ëŠ”ì§€ í•œêµ­ì–´ë¡œ í‰ê°€í•˜ì„¸ìš”. 
       (êµì •ë³¸ì´ ì•„ë‹Œ, ì‚¬ìš©ìê°€ ì²˜ìŒì— ë§í•œ ë‚´ìš©ì´ ì§ˆë¬¸ì— ë§ëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.)

    3. logic_feedback: [ì›ë³¸ ë‹µë³€]ì˜ ë…¼ë¦¬ ì „ê°œë¥¼ í•œêµ­ì–´ë¡œ í‰ê°€í•˜ì„¸ìš”. 
       - 'ì£¼ì œì— ëŒ€í•œ ë‹µë³€ + ë‹¹ì‹œì˜ ê°ì • + ì´ìœ 'ì˜ êµ¬ì¡°ê°€ ì•„ë‹ˆë¼ë©´, ê·¸ë ‡ê²Œ ê³ ì¹˜ëŠ”ê²Œ ì¢‹ë‹¤ê³  ì¡°ì–¸í•˜ì„¸ìš”.
       - ë¶€ì¡±í•˜ë‹¤ë©´ ìœ„ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ë¼ëŠ” ê°€ì´ë“œë¥¼ í¬í•¨í•˜ì„¸ìš”.

    4. fluency_feedback: [ì›ë³¸ ë‹µë³€]ì˜ ë°œí™”ëŸ‰ê³¼ ìœ ì°½ì„±ì„ í•œêµ­ì–´ë¡œ í‰ê°€í•˜ì„¸ìš”.
       - [í•œêµ­ì–´ ì˜ë„]ì™€ ë¹„êµí–ˆì„ ë•Œ ì˜ì–´ ë‹µë³€ì—ì„œ ë¹ ì§„ ë¶€ë¶„ì´ë‚˜ ì™œê³¡ëœ ë‚´ìš©ì´ ìˆëŠ”ì§€ ëŒ€ì¡° ë¶„ì„ì„ í¬í•¨í•˜ì„¸ìš”.
       - [í•œêµ­ì–´ ì˜ë„]ì˜ ë¶„ëŸ‰ì— ë¹„í•´ ì˜ì–´ ë‹µë³€ì´ í˜„ì €íˆ ì§§ë‹¤ë©´ ìœ ì°½ì„± ë¶€ì¡±ì„ ì§€ëª©í•˜ì„¸ìš”.
       - 2ë¬¸ì¥ ì´í•˜: ì‹¬ê°í•œ ì§€ì , 4ë¬¸ì¥ ì´í•˜: ë³´ê°• ì¡°ì–¸, 5ë¬¸ì¥ ì´ìƒ: ì¹­ì°¬.
       - í‘œí˜„ì˜ ë‹¤ì–‘ì„±ì€ ì§€ë‚˜ì¹˜ê²Œ ì—„ê²©í•˜ì§€ ì•Šê²Œ, ê²©ë ¤ ìœ„ì£¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë„ˆë¬´ ë‹¨ì¡°ë¡­ë‹¤ë©´ ê·¸ë•Œë§Œ ì§€ì í•˜ì„¸ìš”.
    
    ì£¼ì˜: relevance_feedback, logic_feedback, fluency_feedbackì€ ì ˆëŒ€ë¡œ [êµì •ëœ ë¬¸ì¥ë“¤] ê¸°ì¤€ì´ ì•„ë‹Œ, [ì›ë³¸ ë‹µë³€]ì˜ ìˆ˜ì¤€ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. fluency_feedback í•­ëª©ì€ [ì›ë³¸ ë‹µë³€]ê³¼ [í•œêµ­ì–´ ì˜ë„] ì‚¬ì´ì˜ ê°„ê·¹ë„ ì²´í¬í•˜ì„¸ìš”.
    """
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "response_mime_type": "application/json",
            "response_schema": {
                "type": "object",
                "properties": {
                    "improved_answer": {"type": "string"},
                    "relevance_feedback": {"type": "string"},
                    "logic_feedback": {"type": "string"},
                    "fluency_feedback": {"type": "string"}
                },
                "required": ["improved_answer", "relevance_feedback", "logic_feedback", "fluency_feedback"]
            }
        }
    }

    async with httpx.AsyncClient() as client:
        response = await client.post(GEMINI_URL, headers=headers, json=payload, timeout=30.0)
        res_json = response.json()
    
    print(f"ğŸ“Š [Step 2] ì›ë³¸ ë° ì˜ë„ ëŒ€ì¡° ì¢…í•© í”¼ë“œë°± ì™„ë£Œ ({time.perf_counter() - start_time:.2f}s)")
    return json.loads(res_json['candidates'][0]['content']['parts'][0]['text'])

# --- API ì—”ë“œí¬ì¸íŠ¸ ---

@app.post(
    "/v1/analyze", 
    response_model=CombinedResponse,
    summary="ì‚¬ìš©ì ë‹µë³€ AI ì¢…í•© ë¶„ì„",
    description="ì‚¬ìš©ìì˜ ì˜ì–´ ë‹µë³€ê³¼ í•œêµ­ì–´ ì˜ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ë²• êµì • ë° AL ê¸°ì¤€ í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤."
)
async def analyze_voice_text(request: AnalysisRequest):
    total_start = time.perf_counter()
    try:
        # 1. ë¬¸ë²• ë° í•„ëŸ¬ êµì •
        sentence_details = await analyze_sentences_gemini(request.user_answer)
        
        # êµì •ëœ ë¬¸ì¥ë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        corrected_text = " ".join([s['improved_text'] for s in sentence_details])
        
        # 2. í•œêµ­ì–´ ì˜ë„ ëŒ€ì¡° ë° ì¢…í•© í”¼ë“œë°± ìƒì„± (ìˆœì°¨ ì‹¤í–‰)
        overall_res = await analyze_overall_gemini(
            request.question_text, 
            request.user_answer, 
            corrected_text,
            request.user_korean_script
        )
        
        total_duration = time.perf_counter() - total_start
        print(f"âœ¨ [ì „ì²´ ë¶„ì„ ì™„ë£Œ] ì´ ì†Œìš” ì‹œê°„: {total_duration:.2f}s")
        
        return {**overall_res, "sentence_details": sentence_details}
        
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# --- ë¼ìš°í„° ë“±ë¡ ---
from exam_feedback import router as exam_router
app.include_router(exam_router, prefix="/v1")